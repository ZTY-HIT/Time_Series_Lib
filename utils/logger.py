import logging
import os
import json
import time
import pandas as pd
from pathlib import Path
from datetime import datetime

class ExperimentLogger:
    """å®éªŒæ—¥å¿—è®°å½•å™¨"""
    
    def __init__(self, log_dir="logs"):
        self.log_dir = log_dir
        os.makedirs(log_dir, exist_ok=True)
        self.setup_logging()
    
    
    def setup_logging(self):
        """è®¾ç½®æ—¥å¿—é…ç½®"""
        import sys
        import io
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        log_file = os.path.join(self.log_dir, f"experiment_{timestamp}.log")
            
        # ä¸ºå¤„ç†å™¨æŒ‡å®šUTF-8ç¼–ç 
        file_handler = logging.FileHandler(log_file, encoding='utf-8')
        # ä¸º stdout åˆ›å»ºä¸€ä¸ªä½¿ç”¨ UTF-8 ç¼–ç çš„æ–‡æœ¬åŒ…è£…å™¨ï¼Œé¿å…è°ƒç”¨ä¸å­˜åœ¨çš„ setEncoding
        stream = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', line_buffering=True)
        stream_handler = logging.StreamHandler(stream)
            
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[file_handler, stream_handler]
        )
        self.logger = logging.getLogger(__name__)
    
    def log_experiment_start(self, config):
        """è®°å½•å®éªŒå¼€å§‹"""
        self.logger.info("ğŸš€ å¼€å§‹å®éªŒ")
        self.logger.info(f"å®éªŒé…ç½®: {json.dumps(config, indent=2, ensure_ascii=False)}")
    
    def log_imputation_result(self, dataset, pattern, rate, imputer, metrics):
        """è®°å½•å¡«è¡¥ç»“æœ"""
        self.logger.info(
            f"ğŸ“Š å¡«è¡¥ç»“æœ - æ•°æ®é›†: {dataset}, æ¨¡å¼: {pattern}, "
            f"ç¼ºå¤±ç‡: {rate}, æ–¹æ³•: {imputer}, RMSE: {metrics.get('RMSE_imp', 'N/A'):.4f}"
        )
    
    def log_forecast_result(self, dataset, model, metrics, skill_score=None):
        """è®°å½•é¢„æµ‹ç»“æœ"""
        msg = f"ğŸ“ˆ é¢„æµ‹ç»“æœ - æ•°æ®é›†: {dataset}, æ¨¡å‹: {model}, RMSE: {metrics.get('RMSE_pred', 'N/A'):.4f}"
        if skill_score is not None:
            msg += f", Skill Score: {skill_score:.2f}%"
        self.logger.info(msg)
    
    def log_error(self, error_msg):
        """è®°å½•é”™è¯¯ä¿¡æ¯"""
        self.logger.error(f"âŒ é”™è¯¯: {error_msg}")
    
    def save_results(self, results, filename):
        """ä¿å­˜ç»“æœåˆ°æ–‡ä»¶"""
        results_dir = "results"
        os.makedirs(results_dir, exist_ok=True)
        
        filepath = os.path.join(results_dir, filename)
        with open(filepath, 'w', encoding='utf-8') as f:
            if filename.endswith('.json'):
                json.dump(results, f, indent=2, ensure_ascii=False)
            else:
                f.write(str(results))
        
        self.logger.info(f"ğŸ’¾ ç»“æœå·²ä¿å­˜: {filepath}")
class ResultsManager:
    """ğŸ†• æ–°å¢ï¼šå®éªŒç»“æœç®¡ç†å™¨ - å®æ—¶æ›´æ–°å’Œè¦†ç›–å†™å…¥"""
    
    def __init__(self, results_dir="results"):
        self.results_dir = Path(results_dir)
        self.results_dir.mkdir(exist_ok=True)
        
    def update_forecast_results(self, result_dict, filename="forecast_results.csv"):
        """
        æ›´æ–°é¢„æµ‹ç»“æœCSVæ–‡ä»¶
        
        Parameters:
        - result_dict: å•æ¬¡å®éªŒç»“æœå­—å…¸
        - filename: ç»“æœæ–‡ä»¶å
        """
        file_path = self.results_dir / filename
        
        # æ·»åŠ æ—¶é—´æˆ³
        result_dict['timestamp'] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        # åˆ›å»ºå”¯ä¸€æ ‡è¯†ï¼ˆç”¨äºè¦†ç›–ç›¸åŒé…ç½®çš„ç»“æœï¼‰
        config_id = self._generate_config_id(result_dict)
        result_dict['config_id'] = config_id
        
        if file_path.exists():
            # è¯»å–ç°æœ‰ç»“æœ
            existing_df = pd.read_csv(file_path)
            
            # æ£€æŸ¥æ˜¯å¦å­˜åœ¨ç›¸åŒé…ç½®çš„ç»“æœ
            mask = existing_df['config_id'] == config_id
            if mask.any():
                # è¦†ç›–æ›´æ–°ç°æœ‰ç»“æœ
                for key, value in result_dict.items():
                    existing_df.loc[mask, key] = value
                print(f"ğŸ“ æ›´æ–°ç°æœ‰å®éªŒç»“æœ: {config_id}")
            else:
                # æ·»åŠ æ–°ç»“æœ
                new_df = pd.DataFrame([result_dict])
                existing_df = pd.concat([existing_df, new_df], ignore_index=True)
                print(f"âœ… æ·»åŠ æ–°å®éªŒç»“æœ: {config_id}")
        else:
            # åˆ›å»ºæ–°æ–‡ä»¶
            existing_df = pd.DataFrame([result_dict])
            print(f"ğŸ†• åˆ›å»ºå®éªŒç»“æœæ–‡ä»¶ï¼Œæ·»åŠ : {config_id}")
        
        # ä¿å­˜æ–‡ä»¶
        existing_df.to_csv(file_path, index=False)
        print(f"ğŸ’¾ å®éªŒç»“æœå·²ä¿å­˜: {file_path}")
        
        return existing_df
    
    def update_csv_results(self, result_dict, file_path, config_keys=None):
        """
        ğŸ†• é€šç”¨æ–¹æ³•ï¼šæ›´æ–°ä»»ä½• CSV ç»“æœæ–‡ä»¶ï¼Œå®ç°å®æ—¶è®°å½•å’Œè¦†ç›–åŠŸèƒ½
        
        Parameters:
        - result_dict: å•æ¬¡å®éªŒç»“æœå­—å…¸
        - file_path: CSV æ–‡ä»¶è·¯å¾„
        - config_keys: ç”¨äºç”Ÿæˆå”¯ä¸€æ ‡è¯†çš„é”®åˆ—è¡¨ï¼ˆé»˜è®¤ä½¿ç”¨æ‰€æœ‰æ ‡å‡†é…ç½®é”®ï¼‰
        """
        file_path = Path(file_path)
        file_path.parent.mkdir(parents=True, exist_ok=True)
        
        # ç¡®å®šé…ç½®é”®
        if config_keys is None:
            config_keys = ['dataset', 'pattern', 'rate', 'imputer', 'model', 'forecast_steps']
        
        # åˆ›å»ºå”¯ä¸€æ ‡è¯†
        config_id = self._generate_config_id(result_dict, config_keys)
        
        # æ·»åŠ æ—¶é—´æˆ³ï¼ˆå¯é€‰ï¼‰
        if 'timestamp' not in result_dict:
            result_dict['timestamp'] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        if file_path.exists():
            # è¯»å–ç°æœ‰ç»“æœ
            existing_df = pd.read_csv(file_path)
            
            # æ£€æŸ¥æ˜¯å¦å­˜åœ¨ç›¸åŒé…ç½®çš„ç»“æœ
            if 'config_id' in existing_df.columns:
                mask = existing_df['config_id'] == config_id
            else:
                # å¦‚æœæ²¡æœ‰ config_id åˆ—ï¼ŒåŠ¨æ€åˆ›å»ºåŒ¹é…æ¡ä»¶
                mask = pd.Series([True] * len(existing_df))
                for key in config_keys:
                    if key in existing_df.columns and key in result_dict:
                        mask = mask & (existing_df[key] == result_dict[key])
            
            if mask.any() and mask.sum() > 0:
                # è¦†ç›–æ›´æ–°ç°æœ‰ç»“æœ
                for key, value in result_dict.items():
                    if key in existing_df.columns:
                        existing_df.loc[mask, key] = value
                    else:
                        # å¦‚æœåˆ—ä¸å­˜åœ¨ï¼Œæ·»åŠ æ–°åˆ—
                        existing_df[key] = None
                        existing_df.loc[mask, key] = value
                print(f"ğŸ“ æ›´æ–°ç°æœ‰è®°å½•: {config_id} -> {file_path.name}")
            else:
                # æ·»åŠ æ–°ç»“æœ
                new_df = pd.DataFrame([result_dict])
                existing_df = pd.concat([existing_df, new_df], ignore_index=True)
                print(f"âœ… æ·»åŠ æ–°è®°å½•: {config_id} -> {file_path.name}")
        else:
            # åˆ›å»ºæ–°æ–‡ä»¶
            existing_df = pd.DataFrame([result_dict])
            print(f"ğŸ†• åˆ›å»ºæ–‡ä»¶: {file_path.name}ï¼Œæ·»åŠ : {config_id}")
        
        # ç¡®ä¿ä¿å­˜ config_id ç”¨äºåç»­æ›´æ–°
        existing_df['config_id'] = config_id
        
        # ä¿å­˜æ–‡ä»¶
        existing_df.to_csv(file_path, index=False)
        print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜: {file_path}")
        
        return existing_df
    
    def _generate_config_id(self, result_dict, config_keys=None):
        """ç”Ÿæˆé…ç½®å”¯ä¸€æ ‡è¯†"""
        if config_keys is None:
            config_keys = ['dataset', 'pattern', 'rate', 'imputer', 'model', 'forecast_steps']
        
        id_parts = []
        for key in config_keys:
            if key in result_dict:
                id_parts.append(str(result_dict[key]))
            else:
                id_parts.append('')
        return '_'.join(id_parts).replace(' ', '_')
    
    def calculate_skill_scores(self, results_file="forecast_results.csv"):
        """
        è®¡ç®—æ‰€æœ‰ç»“æœçš„ Skill Scoreï¼ˆåŸºäº mean æ–¹æ³•ä½œä¸º baselineï¼‰
        """
        file_path = self.results_dir / results_file
        
        if not file_path.exists():
            print("âš ï¸  ç»“æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œæ— æ³•è®¡ç®— Skill Score")
            return None
        
        df = pd.read_csv(file_path)
        
        if len(df) == 0:
            print("âš ï¸  ç»“æœæ–‡ä»¶ä¸ºç©ºï¼Œæ— æ³•è®¡ç®— Skill Score")
            return None
            
        # è®¡ç®—æ¯ä¸ªé…ç½®çš„ baseline RMSEï¼ˆä½¿ç”¨ mean æ–¹æ³•ï¼‰
        skill_scores = []
        
        for _, row in df.iterrows():
            # æ‰¾åˆ°ç›¸åŒé…ç½®çš„ baseline ç»“æœï¼ˆä½¿ç”¨ mean æ–¹æ³•ï¼‰
            baseline_mask = (
                (df['dataset'] == row['dataset']) &
                (df['pattern'] == row['pattern']) &
                (df['rate'] == row['rate']) &
                (df['model'] == row['model']) &
                (df['forecast_steps'] == row['forecast_steps']) &
                (df['imputer'] == 'mean')  # baseline æ–¹æ³•
            )
            
            baseline_results = df[baseline_mask]
            
            if len(baseline_results) > 0 and 'RMSE_pred' in baseline_results.columns:
                baseline_rmse = baseline_results.iloc[0]['RMSE_pred']
                current_rmse = row['RMSE_pred'] if 'RMSE_pred' in row else 0
                
                # è®¡ç®— Skill Score
                if baseline_rmse > 0 and current_rmse > 0:
                    skill_score = 100 * (1 - current_rmse / baseline_rmse)
                else:
                    skill_score = 0.0
            else:
                skill_score = 0.0  # æ²¡æœ‰ baseline æ•°æ®
            
            skill_scores.append(skill_score)
        
        # æ›´æ–° Skill Score åˆ—
        df['skill_score'] = skill_scores
        
        # ä¿å­˜æ›´æ–°åçš„ç»“æœ
        df.to_csv(file_path, index=False)
        print(f"ğŸ“Š å·²æ›´æ–° Skill Score: {len(skill_scores)} æ¡è®°å½•")
        
        return df
    def update_forecast_metrics(self, result_dict, output_dir="forecast_outputs"):
        """
        ä¸“é—¨æ›´æ–° forecast_metrics.csv æ–‡ä»¶
        """
        output_path = Path(output_dir) / "forecast_metrics.csv"
        return self.update_csv_results(result_dict, output_path)