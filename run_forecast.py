#!/usr/bin/env python3
"""
é¢„æµ‹å®éªŒä¸»è„šæœ¬
"""

import os
import argparse
import pandas as pd
import numpy as np
from pathlib import Path
import time
import psutil

from utils import DataLoader, Evaluator, ExperimentLogger, Visualizer, ResultsManager 
from config import load_config, get_forecast_class

def run_forecast_experiment():
    """è¿è¡Œé¢„æµ‹å®éªŒ"""
    parser = argparse.ArgumentParser(description='è¿è¡Œé¢„æµ‹å®éªŒ')
    parser.add_argument('--dataset', type=str, help='æ•°æ®é›†åç§°')
    parser.add_argument('--pattern', type=str, help='ç¼ºå¤±æ¨¡å¼')
    parser.add_argument('--rate', type=float, help='ç¼ºå¤±ç‡')
    parser.add_argument('--imputer', type=str, help='å¡«è¡¥æ–¹æ³•')
    parser.add_argument('--model', type=str, help='é¢„æµ‹æ¨¡å‹')
    parser.add_argument('--forecast_steps', type=int, default=10, help='é¢„æµ‹æ­¥æ•°')
    parser.add_argument('--all', action='store_true', help='è¿è¡Œæ‰€æœ‰ç»„åˆ')
    
    args = parser.parse_args()
    config = load_config()
    logger = ExperimentLogger()
    data_loader = DataLoader()
    evaluator = Evaluator()
    visualizer = Visualizer()
    results_manager = ResultsManager()
    
    logger.log_experiment_start(config)
    
    # è·å–å®éªŒç»„åˆ
    if args.all:
        experiments = generate_all_forecast_experiments(config)
    else:
        experiments = [{
            'dataset': args.dataset or config['datasets']['default'],
            'pattern': args.pattern or config['missing_patterns']['default'],
            'rate': args.rate or config['missing_rates']['default'],
            'imputer': args.imputer or config['imputers']['default'],
            'model': args.model or config['forecast_models']['default'],
            'forecast_steps': args.forecast_steps
        }]
    
    results = []
    
    for exp in experiments:
        try:
            print(f"\nğŸ”§ è¿è¡Œé¢„æµ‹å®éªŒ: {exp}")
            
            # åŠ è½½å¡«è¡¥ç»“æœ
            imputed_data = load_imputation_result(exp)
            if imputed_data is None:
                print(f"âš ï¸  æœªæ‰¾åˆ°å¡«è¡¥ç»“æœ: {exp}ï¼Œè·³è¿‡")
                continue
            
            # åŠ è½½åŸå§‹æ•°æ®ç”¨äºè®¡ç®—æŒ‡æ ‡
            original_data = data_loader.load_original_data(exp['dataset'])
            
            # éªŒè¯æ—¶é—´æˆ³
            if not data_loader.validate_timestamp_column(original_data):
                raise ValueError(f"æ•°æ®é›† {exp['dataset']} ç¬¬ä¸€åˆ—ä¸æ˜¯æœ‰æ•ˆæ—¶é—´æˆ³")
            
            # è·å–é¢„æµ‹æ¨¡å‹
            forecast_class = get_forecast_class(exp['model'])
            if not forecast_class:
                raise ValueError(f"æœªçŸ¥çš„é¢„æµ‹æ¨¡å‹: {exp['model']}")
            
            # å®ä¾‹åŒ–æ¨¡å‹ï¼ˆè¿™é‡Œå¯ä»¥æ ¹æ®éœ€è¦ä¼ é€’å‚æ•°ï¼‰
            forecast_class = get_forecast_class(exp['model'])
            if not forecast_class:
                raise ValueError(f"æœªçŸ¥çš„é¢„æµ‹æ¨¡å‹: {exp['model']}")
            
            # æ‰§è¡Œé¢„æµ‹
            start_time = time.time()
            process = psutil.Process()
            
            # ä½¿ç”¨å¡«è¡¥åçš„æ•°æ®è¿›è¡Œé¢„æµ‹
            forecaster = forecast_class()
            # ä½¿ç”¨å¡«è¡¥åçš„æ•°æ®è¿›è¡Œé¢„æµ‹
            forecast_result = forecaster.forecast(
                imputed_data, 
                forecast_steps=exp['forecast_steps'],
                plot=False  # åœ¨ä¸»è„šæœ¬ä¸­ç»Ÿä¸€ç»˜åˆ¶
            )
            
            end_time = time.time()
            
            # å‡†å¤‡çœŸå®å€¼ç”¨äºè¯„ä¼°
            ts, pred_truth, freq = data_loader.prepare_forecast_data(
                original_data, exp['forecast_steps']
            )
            
            # è®¡ç®—é¢„æµ‹æŒ‡æ ‡
            forecast_metrics = evaluator.calculate_forecast_metrics(
                pred_truth.values, forecast_result.values
            )
            
            computational_metrics = evaluator.calculate_computational_metrics(
                start_time, end_time, process
            )
            
            # ğŸ†• ä¿®æ”¹ï¼šSkill Score ç°åœ¨åœ¨ ResultsManager ä¸­ç»Ÿä¸€è®¡ç®—
            skill_score = 0.0  # ä¸´æ—¶å€¼ï¼Œåé¢ä¼šé‡æ–°è®¡ç®—
            
            # ä¿å­˜ç»“æœåˆ°å­—å…¸
            result = {
                'dataset': exp['dataset'],
                'pattern': exp['pattern'],
                'rate': exp['rate'],
                'imputer': exp['imputer'],
                'model': exp['model'],
                'forecast_steps': exp['forecast_steps'],
                **forecast_metrics,
                'skill_score': skill_score,
                **computational_metrics
            }
            results.append(result)

             # ğŸ†• ä¿®æ”¹ï¼šä½¿ç”¨æ–°çš„å®æ—¶æ›´æ–°æ–¹æ³•ä¿å­˜ç»“æœ
            results_manager.update_forecast_results(result)
            
            # è®°å½•æ—¥å¿—
            logger.log_forecast_result(
                exp['dataset'], exp['model'], forecast_metrics, skill_score
            )
            
            # ä¿å­˜é¢„æµ‹ç»“æœå’Œå›¾è¡¨
            save_forecast_result(forecast_result, exp, pred_truth, visualizer)
            
        except Exception as e:
            logger.log_error(f"é¢„æµ‹å®éªŒå¤±è´¥ {exp}: {str(e)}")
            continue
    
    # ğŸ†• ä¿®æ”¹ï¼šæ‰€æœ‰å®éªŒå®Œæˆåç»Ÿä¸€è®¡ç®— Skill Score
    if results:
        print("\nğŸ“Š æ­£åœ¨è®¡ç®—æ‰€æœ‰å®éªŒçš„ Skill Score...")
        updated_df = results_manager.calculate_skill_scores()
    
        # ğŸ†• ä¿®æ”¹ï¼šä½¿ç”¨é€šç”¨æ–¹æ³•å®æ—¶æ›´æ–° forecast_metrics.csv
        if updated_df is not None:
            output_dir = Path(config['paths']['outputs_forecast'])
        
            # ä¸ºæ¯ä¸ªç»“æœæ›´æ–° forecast_metrics.csv
            for _, row in updated_df.iterrows():
                result_dict = row.to_dict()
                # ä½¿ç”¨ä¸“é—¨çš„ forecast metrics æ–¹æ³•
                results_manager.update_forecast_metrics(result_dict, output_dir)
        
            print(f"ğŸ’¾ é¢„æµ‹æŒ‡æ ‡å·²å®æ—¶æ›´æ–°")
    
        # ä¿æŒåŸæœ‰çš„ JSON ä¿å­˜åŠŸèƒ½
        logger.save_results(results, 'forecast_results.json')

def generate_all_forecast_experiments(config):
    """ç”Ÿæˆæ‰€æœ‰é¢„æµ‹å®éªŒç»„åˆ"""
    experiments = []
    
    # é¦–å…ˆæ£€æŸ¥æœ‰å“ªäº›å¡«è¡¥ç»“æœå¯ç”¨
    impute_output_dir = Path(config['paths']['outputs_impute'])
    if not impute_output_dir.exists():
        print("âš ï¸  æœªæ‰¾åˆ°å¡«è¡¥ç»“æœï¼Œè¯·å…ˆè¿è¡Œå¡«è¡¥å®éªŒ")
        return experiments
    
    for dataset_dir in impute_output_dir.iterdir():
        if dataset_dir.is_dir():
            dataset = dataset_dir.name
            for imputed_file in dataset_dir.glob("*_imputed.csv"):
                # è§£ææ–‡ä»¶åè·å–å‚æ•°
                filename = imputed_file.stem
                parts = filename.split('_')
                pattern = parts[0]
                rate = float(parts[1].replace('rate', ''))
                imputer = parts[2]
                
                for model in config['forecast_models']['available']:
                    experiments.append({
                        'dataset': dataset,
                        'pattern': pattern,
                        'rate': rate,
                        'imputer': imputer,
                        'model': model,
                        'forecast_steps': 10
                    })
    
    return experiments

def load_imputation_result(exp_config):
    """åŠ è½½å¡«è¡¥ç»“æœ"""
    config = load_config()
    filename = f"{exp_config['pattern']}_rate{exp_config['rate']}_{exp_config['imputer']}_imputed.csv"
    file_path = Path(config['paths']['outputs_impute']) / exp_config['dataset'] / filename
    
    if file_path.exists():
        df = pd.read_csv(file_path)
        print(f"ğŸ“ åŠ è½½å¡«è¡¥æ•°æ®: {file_path}")
        print(f"  æ•°æ®å½¢çŠ¶: {df.shape}")
        print(f"  æ•°æ®åˆ—å: {list(df.columns)}")
        print(f"  å‰5è¡Œæ—¶é—´åˆ—: {df.iloc[:5, 0].tolist()}")
        return df
    else:
        print(f"âŒ å¡«è¡¥ç»“æœæ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        return None

def save_forecast_result(forecast_result, exp_config, true_values, visualizer):
    """ä¿å­˜é¢„æµ‹ç»“æœ"""
    config = load_config()
    output_dir = Path(config['paths']['outputs_forecast']) / exp_config['dataset']
    output_dir.mkdir(exist_ok=True)
    
    # ä¿å­˜é¢„æµ‹æ•°æ®
    filename = f"{exp_config['pattern']}_rate{exp_config['rate']}_{exp_config['imputer']}_{exp_config['model']}_forecast.csv"
    forecast_result.to_csv(output_dir / filename)
    
    # ä¿å­˜é¢„æµ‹å›¾è¡¨ï¼ˆä½¿ç”¨å®‰å…¨çš„æ–¹æ³•ï¼‰
    plot_filename = f"{exp_config['pattern']}_rate{exp_config['rate']}_{exp_config['imputer']}_{exp_config['model']}_plot.png"
    plot_path = output_dir / plot_filename
    
    try:
        # é¦–å…ˆå°è¯•å¸¸è§„ç»˜å›¾
        visualizer.plot_forecast_results(
            true_values, forecast_result, 
            f"{exp_config['model']} ({exp_config['imputer']})", 
            exp_config['dataset'],
            save_path=plot_path
        )
    except Exception as e:
        print(f"âš ï¸  å¸¸è§„ç»˜å›¾å¤±è´¥ï¼Œä½¿ç”¨å®‰å…¨ç»˜å›¾: {e}")
        # å¦‚æœå¸¸è§„ç»˜å›¾å¤±è´¥ï¼Œä½¿ç”¨å®‰å…¨ç»˜å›¾
        if hasattr(visualizer, 'plot_forecast_results_safe'):
            visualizer.plot_forecast_results_safe(
                true_values, forecast_result, 
                f"{exp_config['model']} ({exp_config['imputer']})", 
                exp_config['dataset'],
                save_path=plot_path
            )
        else:
            print(f"âŒ å®‰å…¨ç»˜å›¾æ–¹æ³•ä¹Ÿä¸å¯ç”¨ï¼Œè·³è¿‡ç»˜å›¾")

if __name__ == "__main__":
    run_forecast_experiment()